We'll create docker images for our application so we can run it in remote servers. We'll create an image for backend and an image for frontend. Creating two separated images increase the flexibility of deployment.

First we must make sure a **requirements.txt** has included all Python packages needed:

>cd backend
>
>pip freeze > requirements.txt

Then we'll create two docker build files for building images of backend and frontend.

Create file **Dockerfile-backend** in repo root folder:

```
FROM python:3.11-slim
WORKDIR /myapp

# 0. Install system dependencies (curl)
RUN apt-get update && apt-get install -y --no-install-recommends curl \
    && rm -rf /var/lib/apt/lists/*

# 1. Install backend deps
COPY backend/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 2. Copy backend source
COPY backend/ ./backend

# 3. Add backend to Python path and run FastAPI with uvicorn
ENV PYTHONPATH=/myapp/backend
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

Create file **Dockerfile-frontend** in repo root folder:

```
FROM node:24 AS build
WORKDIR /app
COPY frontend/package*.json ./frontend/
WORKDIR /app/frontend
RUN npm ci
COPY frontend/ .
RUN npm run build

FROM nginx:stable-alpine
COPY --from=build /app/frontend/dist /usr/share/nginx/html

# Copy custom Nginx config
COPY frontend/nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```
Note we use Vite in local development host as frontend web server, but we use nginx in Docker. For this reason we need a nginx config file to setup it.

Add file **frontend/nginx.conf**:

```
server {
    listen 80;

    # Serve frontend static files
    root /usr/share/nginx/html;
    index index.html;
    location / {
        try_files $uri /index.html;
    }

    # Reverse proxy for API calls
    location /api/ {
        proxy_pass http://backend.mylearningapp.local:8000/;  # backend is container name in Docker network
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;

        # Strip /api prefix before forwarding
        rewrite ^/api/(.*)$ /$1 break;
    }
}
```
Note in nginx we'll proxy all api requests to the backend docker. Also note we name the backend as **backend.mylearningapp.local**. The host naming style here is to make sure this hostname can be correctly resolved in AWS running service, we'll cover this part later.

Now create **docker-compose.yml** in repo root folder, it is used to bring up the above dockers:

```
version: "3.9"

services:
  postgres:
    image: postgres:17
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}  # taken from host env
      POSTGRES_DB: userdb
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 2s
      timeout: 5s
      retries: 15
    networks:
      - myapp-network

  backend:
    restart: "no"
    image: my-backend:latest
    container_name: backend.mylearningapp.local
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      RUNNING_IN_DOCKER: 1
    ports:
      - "8000:8000"
    networks:
      - myapp-network

  frontend:
    restart: "no"
    image: my-frontend:latest
    container_name: frontend
    depends_on:
      backend:
        condition: service_started
    ports:
      - "80:80"
    networks:
      - myapp-network

networks:
  myapp-network:
    driver: bridge
```

Something worth noting in compose file:

- we created a network "myapp-network", all containers are running in this network so frontend can find backend by its name, and backend can find database server by its name.
- a postgres docker is running, this is used as the database server.
- two environment variables are added for backend docker: POSTGRES_PASSWORD is used to store database password. RUNNING_IN_DOCKER is used to let backend code logic check if application is running in Docker.

To utilize these two variables, we need to update backend code.

In **backend/app/users/userdb_utils.py**:

Update get_db_host() . If application is running Docker, then it will use the postgres cotainer name as the database host name:

```
def get_db_host() -> str:
    # If running inside Docker, use docker network hostname
    if os.getenv("RUNNING_IN_DOCKER"):
        print("ðŸ³ Detected Docker via RUNNING_IN_DOCKER env, using 'postgres'")
        return "postgres"
    
    return "localhost"
```

Update read_postgres_password(). When running in Docker, we'll set the database password in an environment variable:

```
def read_postgres_password() -> str:
    """
    Read PostgreSQL password from environment variable or file.
    
    Returns:
        str: The PostgreSQL password
        
    Raises:
        RuntimeError: If password is not found in environment variable or file
    """
    # try to get from environment variable (for CI/CD in Github Actions)
    postgres_password = os.getenv("POSTGRES_PASSWORD")
    if postgres_password:
        print(f"ðŸ³ Detected POSTGRES_PASSWORD")
        return postgres_password
    
    tokens_path = Path(__file__).resolve().parent.parent.parent / "tokens" / "postgresql.txt"
    try:
        return tokens_path.read_text(encoding="utf-8").strip()
    except FileNotFoundError:
        raise RuntimeError(f"PostgreSQL password not found in environment variable POSTGRES_PASSWORD or file at: {tokens_path}")
```

Update seed_database(). When running in Docker, the database server is started without the table we neened. So we need to check and create the table if it doesn't exist:

```
def seed_database():
    """Seed the database with test users."""
    try:
        db_host = get_db_host()
        password = read_postgres_password()
        # Get database connection
        
        database_url = f"postgresql+psycopg2://postgres:{password}@{db_host}:5432/userdb"
        
        # Create engine and session
        engine = create_engine(database_url, pool_pre_ping=True)
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
        
        # Ensure the users table exists (supports custom __tablename__ changes)
        inspector = inspect(engine)
        users_table_name = Users.__tablename__
        if not inspector.has_table(users_table_name):
            # Create the table using raw SQL with IF NOT EXISTS and anonymous constraints
            create_sql = f"""
            CREATE TABLE IF NOT EXISTS {users_table_name} (
                id SERIAL PRIMARY KEY,
                name VARCHAR(40) NOT NULL UNIQUE,
                gender VARCHAR(6) NOT NULL CHECK (gender IN ('Male','Female')),
                age INTEGER NOT NULL CHECK (age >= 0 AND age <= 100)
            )
            """
            with engine.begin() as conn:
                conn.execute(text(create_sql))
        
        # Create session
        db = SessionLocal()
        
        try:
            # Check if users already exist
            existing_users = db.query(Users).count()
            if existing_users > 0:
                return
            
            # Create test users
            test_users = [
                Users(name="Alice", gender="Female", age=25),
                Users(name="Bob", gender="Male", age=30),
            ]
            
            # Add users to database
            for user in test_users:
                db.add(user)
            
            # Commit changes
            db.commit()

            # Verify the seeded users can be retrieved
            retrieved = db.query(Users).filter(Users.name.in_([u.name for u in test_users])).all()
            retrieved_names = {u.name for u in retrieved}
            expected_names = {u.name for u in test_users}
            if retrieved_names != expected_names:
                sys.exit(1)
            
            for user in retrieved:
                print(f"  - {user.name} ({user.gender}, age {user.age})")
                
        except Exception as e:
            db.rollback()
            print(f"ðŸ›’ Error seeding database: {e}")
            sys.exit(1)
        finally:
            db.close()
            
    except Exception as e:
        print(f"ðŸ›’ Error connecting to database: {e}")
        sys.exit(1)
```

Now we can proceed to build images:

>docker build -f Dockerfile-frontend -t my-frontend:latest .
>
>docker build -f Dockerfile-backend -t my-backend:latest .

To run the application, we first set the database passord, and then launch the containers:

>export POSTGRES_PASSWORD=\<database password\>
>
>docker-compose up

Verify the application by visting URL "localhost" in web browser. Check if everything works as expected.