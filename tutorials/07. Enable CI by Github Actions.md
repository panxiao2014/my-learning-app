# âš™ï¸ 07. enable CI by Github Actions

Our local development for tutorials is complete and it's time for continuous integration. CI is very helpful for bug detecting in our daily code commitment and it makes sure nothing is brokend with code update.

Github Actions provides support for CI. We'll use it to create two workflows, one is to test our backend API handling functions and one is to test end-to-end user interctions with web page.

Since we use database server in our application and we do not share the password in code, we can store the password in Github secret so the tests running in Github Actions can retrieve it.

Go to Github repository page, navigate to **Settings --> Secrets and variables --> Actions**, click **New repository secret**. Create a secret named **POSTGRES_PASSWORD** ans store the value.

To define the Github Actions flows we need to create a folder under repo root folder:

>.github/workflows

First, we define a workflow to test backend API functions:

**backend_test.yml**:
```
name: Backend Tests
run-name: ${{ github.actor }} is running Backend Tests at ${{ github.event.head_commit.timestamp }}
on:
  push:
    paths:
      - 'backend/**'
      - '.github/workflows/backend_test.yml'

jobs:
  test-backend:
    name: Test backend job
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:17
        ports:
          - 5432:5432
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB: userdb
        options: >-
          --health-cmd="pg_isready -U postgres -d userdb"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    defaults:
      run:
        working-directory: backend
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - run: echo "ðŸ’¡ The ${{ github.repository }} repository has been cloned to the runner."

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - run: echo "ðŸ’¡ The Python setup is complete."

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - run: echo "ðŸ’¡ The pip cache is set up."

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          echo "ðŸ’¡ The dependencies are installed."

      - name: Run backend tests
        env:
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
        run: |
            pytest -m fastapi
            echo "ðŸ’¡ The tests are finished."
```

This file shows how CI is implemented in Github Actions:

* It is triggered when there is code commitment in folder "backend" or the workflow config file itself.
* It runs on Ubuntu platform.
* It retrieves the database password by using secrets.POSTGRES_PASSWORD as we added.
* It installs a Postgresql database first with username and password.
* It then checks out the code and setup Python.
* It calls *pytest -m fastapi* to start test.

We add another file for end-to-end test:

**e2e_deploy.yml**:
```
name: E2E Deploy and Test
run-name: ${{ github.actor }} is running E2E Deploy and Test at ${{ github.event.head_commit.timestamp }}
on: push

jobs:
    e2e-verify:
        name: Docker verify job
        runs-on: ubuntu-latest

        steps:
          - name: Checkout repository
            uses: actions/checkout@v5
          
          - name: Set up Python
            uses: actions/setup-python@v5
            with:
                python-version: '3.11'

          - name: Install test dependencies (pytest, pytest-playwright)
            run: |
                python -m pip install --upgrade pip
                pip install -r backend/requirements.txt

          - name: Install Docker Compose
            run: |
                sudo apt-get update
                sudo apt-get install -y docker-compose

          - name: Install Playwright browsers
            run: |
                playwright install
    
          - name: Build backend image
            run: |
                docker build -f Dockerfile-backend -t my-backend:latest .
                echo "ðŸ’¡ Backend image built."
    
          - name: Build frontend image
            run: |
                docker build -f Dockerfile-frontend -t my-frontend:latest .
                echo "ðŸ’¡ Frontend image built."
    
          - name: Create Docker network
            run: |
                docker network create myapp-network
                echo "ðŸ’¡ Docker network created."

          - name: Run Docker Compose
            env:
              POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
            run: |
                docker-compose -f docker-compose.yml up -d
                echo "ðŸ’¡ Docker containers running." 
    
          - name: Verify backend
            run: |
                sleep 5
                docker ps -a
                curl --fail http://localhost:8000/ping
                echo "ðŸ’¡ Backend verified."
    
          - name: Verify frontend
            env:
              POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
              RUN_IN_GITHUB_ACTIONS: 1
            run: | 
                pytest -m e2e
                echo "ðŸ’¡ Frontend verified."
```
This test works as follows:

* It checks out code and install any necessary packages. 
* It builds backend and frontend dockers images.
* It creates Docker network and runs docker compose just like we run it in local Docker containers.
* It uses *curl* to first check if backend server running in port 8000 is working.
* Then it runs *pytest -m e2e* for end-to-end test.

Note that when running in local host we use Vite as the frontend server and the port is 5173. When running in remote Docker we want to access the web page by using HTTP default port 80. The tests running in Github Actions then will access the web by port 80, so we need to update test cases.

Add a function in file **backend/app/users/userdb_utils.py**:

```
def get_localhost_url() -> str:
    # If running in Github Actions, use 80:
    if os.getenv("RUN_IN_GITHUB_ACTIONS"):
        return "http://localhost:80"
    else:
        return "http://localhost:5173"
```

This function uses environment variable RUN_IN_GITHUB_ACTIONS which we defined in workflow yml file to check if test is running in Github Actions.

Update tests in file **backend/tests/test_webpage.py**:

```
from app.users.userdb_utils import init_database_session, get_localhost_url
```

Add a fixture to get the web URL:

```
@pytest.fixture(scope="module")
def localhost_url():
    return get_localhost_url()
```

Then for each test case use that fixture:
```
def test_click_button_displays_test_ping(page: Page, localhost_url: str):
    # Open the frontend app
    page.goto(localhost_url)
    ...
```

After we push these files to remote repository the two workflows will start to run. Go to Github repository, navigate to **Actions** and we'll see the running workflows.

These workflows will run once we have code pushed to remote repository. We can check their running result and error messages if any of them fails.